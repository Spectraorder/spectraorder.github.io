@inproceedings{chen2026chimera,
  title        = {Chimera: Compositional Image Generation using Part-based Concepting},
  author       = {Yiming Chen* and Shivam Singh* and Agneet Chatterjee and Amit Raj and James Hays and Yezhou Yang and Chitta Baral},
  year         = {2026},
  booktitle    = {Under review at ICLR},
  preview      = {chimera-teaser.png},
  abstract     = {Personalized image generative models are highly proficient at synthesizing images from text or a single image, yet they lack explicit control for composing objects from specific parts of multiple source images without user specified masks or annotations. To address this, we introduce Chimera, a personalized image generation model that generates novel objects by combining specified parts from different source images according to textual instructions. To train our model, we first construct a dataset from a taxonomy built on 464 unique (part, subject) pairs, which we term semantic atoms. From this, we generate 37k prompts and synthesize the corresponding images with a high-fidelity text-to-image model. We train a custom diffusion prior model with part-conditional guidance, which steers the image-conditioning features to enforce both semantic identity and spatial layout. We also introduce an objective metric PartEval to assess the fidelity and compositional accuracy of generation pipelines. Human evaluations and our proposed metric show that Chimera outperforms other baselines by 14% in part alignment and compositional accuracy and 21% in visual quality.},
  arxiv        = {2510.18083},
  html         = {https://chimera-compositional-image-generation.vercel.app/},
  selected     = {true}
}

@inproceedings{yang2025clink,
  title        = {Clink! Chop! Thud! - Learning Object Sounds from Real-World Interactions},
  author       = {Mengyu Yang and Yiming Chen and Haozheng Pei and Siddhant Agarwal and Arun Balajee Vasudevan and James Hays},
  year         = {2025},
  booktitle    = {ICCV},
  preview      = {clink-teaser.png},
  abstract     = {Can a model distinguish between the sound of a spoon hitting a hardwood floor versus a carpeted one? Everyday object interactions produce sounds unique to the objects involved. We introduce the sounding object detection task to evaluate a model's ability to link these sounds to the objects directly involved. Inspired by human perception, our multimodal object-aware framework learns from in-the-wild egocentric videos. To encourage an object-centric approach, we first develop an automatic pipeline to compute segmentation masks of the objects involved to guide the model's focus during training towards the most informative regions of the interaction. A slot attention visual encoder is used to further enforce an object prior. We demonstrate state of the art performance on our new task along with existing multimodal action understanding tasks.},
  arxiv        = {2510.02313},
  html         = {https://clink-chop-thud.github.io/},
  selected     = {true}
}

@inproceedings{chen2025csg,
  title        = {CSG-based ML-supported 3D Translation of Sketches into Game Assets for Game Designers},
  author       = {Yiming Chen and Yihang Liu and Gizem Kayar-Ceylan},
  year         = {2025},
  booktitle    = {The Visual Computer},
  preview      = {csg-teaser.png},
  pages        = {1--13},
  abstract     = {This research project aims to develop a new technique for translating 2D sketches into 3D assets like building models using machine learning and Constructive Solid Geometry (CSG) algorithms. The ability to quickly create 3D building models from simple freehand sketches has widespread applications in fields like architecture and construction. The key innovation is the use of CSG principles to understand geometric elements from sketches, extrude them into 3D, and combine simple shapes to create complex structures.},
  pdf          = {https://doi.org/10.1007/s00371-024-03758-9},
  html         = {https://spectraorder.github.io/CSG-3D-page/},
  selected     = {true}
}

@inproceedings{chen2020patent,
  title        = {A Device for Compressing Garbage in Dustbin},
  author       = {Yiming Chen},
  year         = {2020},
  booktitle    = {China National Intellectual Property Administration (Patent No. CN210823859U)},
  preview      = {dustbin-teaset.png},
  abstract     = {The present invention discloses a device for compressing garbage in a trash bin, comprising: a support plate, a plurality of pillars fixedly disposed below the support plate, a plurality of telescopic pillars connected at one end to the support plate below the support plate, and a compression plate connected to the other end of the telescopic pillars, wherein the pillars are used to extend into the trash bin and support the support plate, and the trash in the trash bin is compressed by controlling the downward movement of the telescopic pillars and the compression plate connected thereto. The present invention is placed above the trash bin so that the pillars can extend into the trash bin. If there is a lot of trash in the trash bin, the telescopic pillars can be controlled to extend downward, thereby controlling the compression plate to compress the trash in the trash bin, freeing up more space and achieving the purpose of fully utilizing the space in the trash bin.},
  html         = {http://epub.cnipa.gov.cn/cred/CN210823859U}
}